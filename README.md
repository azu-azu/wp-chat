# WordPress RAG Chatbot (MVP4)

Advanced RAG (Retrieval-Augmented Generation) chatbot for WordPress sites with OpenAI integration, streaming responses, and citation tracking.

## ğŸš€ Features

- **RAG Generation**: OpenAI GPT-4o mini integration with citation tracking
- **Streaming Responses**: Real-time token delivery for better UX
- **Hybrid Search**: Dense + BM25 + Cross-encoder reranking
- **Citation Tracking**: Source attribution with `[[1]]` references
- **SLO Monitoring**: Performance metrics and alerting
- **Canary Deployment**: Gradual feature rollout
- **CLI Tools**: Interactive testing and management

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ api/                    # FastAPI endpoints
â”‚   â””â”€â”€ chat_api.py        # Main API server
â”œâ”€â”€ cli/                    # Command-line tools
â”‚   â”œâ”€â”€ generate_cli.py    # RAG generation testing
â”‚   â”œâ”€â”€ backup_cli.py      # Backup management
â”‚   â”œâ”€â”€ canary_cli.py      # Canary deployment
â”‚   â””â”€â”€ incident_cli.py    # Incident management
â”œâ”€â”€ core/                   # Core utilities
â”‚   â”œâ”€â”€ config.py          # Configuration management
â”‚   â”œâ”€â”€ cache.py           # Response caching
â”‚   â”œâ”€â”€ rate_limit.py      # Rate limiting
â”‚   â”œâ”€â”€ slo_monitoring.py  # Performance monitoring
â”‚   â””â”€â”€ runbook.py         # Emergency procedures
â”œâ”€â”€ data/                   # Data processing
â”‚   â”œâ”€â”€ fetch_wp.py        # WordPress API fetch
â”‚   â”œâ”€â”€ clean_text.py      # Text cleaning
â”‚   â”œâ”€â”€ build_index.py     # Index building
â”‚   â””â”€â”€ utils_chunk.py     # Text chunking
â”œâ”€â”€ generation/             # RAG generation (MVP4)
â”‚   â”œâ”€â”€ generation.py      # Generation pipeline
â”‚   â”œâ”€â”€ openai_client.py   # OpenAI API client
â”‚   â”œâ”€â”€ prompts.py         # Prompt engineering
â”‚   â””â”€â”€ highlight.py       # Result highlighting
â”œâ”€â”€ management/             # Operations & monitoring
â”‚   â”œâ”€â”€ ab_logging.py      # A/B test logging
â”‚   â”œâ”€â”€ canary_manager.py  # Canary deployment
â”‚   â”œâ”€â”€ dashboard.py       # Monitoring dashboard
â”‚   â”œâ”€â”€ model_manager.py   # Model management
â”‚   â””â”€â”€ backup_manager.py  # Backup operations
â””â”€â”€ retrieval/              # Search & scoring
    â”œâ”€â”€ search_hybrid.py   # Hybrid search
    â”œâ”€â”€ rerank.py          # Cross-encoder reranking
    â”œâ”€â”€ composite_scoring.py # Scoring strategies
    â””â”€â”€ eval_retrieval.py  # Retrieval evaluation
```

## ğŸ“‹ Prerequisites

- Python 3.10+
- OpenAI API key
- macOS/Linux (tested on macOS)

## âš™ï¸ Setup

### 1. Environment Setup
```bash
# Create virtual environment
python -m venv .venv && source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration
Create `.env` file:
```bash
cp .env.example .env
# Edit .env with your settings
```

Required environment variables:
```bash
# .env
WP_BASE_URL=https://your-blog.example.com
OPENAI_API_KEY=sk-proj-your-openai-api-key-here
```

### 3. Data Pipeline
```bash
# Fetch WordPress content
python -m src.data.fetch_wp

# Clean and process text
python -m src.data.clean_text

# Build search index
python -m src.data.build_index
```

## ğŸš€ Running the Application

### API Server
```bash
# Development mode
uvicorn src.api.chat_api:app --reload --port 8080

# Production mode
uvicorn src.api.chat_api:app --host 0.0.0.0 --port 8080
```

### CLI Tools

#### RAG Generation Testing
```bash
# Health check
python -m src.cli.generate_cli --health

# Single question
python -m src.cli.generate_cli "Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®åŸºæœ¬ã‚’æ•™ãˆã¦"

# Interactive mode (recommended)
python -m src.cli.generate_cli --interactive

# With options
python -m src.cli.generate_cli "Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œã‚Šæ–¹ã‚’æ•™ãˆã¦" --topk 5 --mode hybrid --rerank
```

#### Other CLI Tools
```bash
# Backup management
python -m src.cli.backup_cli --help

# Canary deployment
python -m src.cli.canary_cli --help

# Incident management
python -m src.cli.incident_cli --help
```

## ğŸ”§ API Endpoints

### Search & Ask
```bash
# Traditional search
curl -X POST http://localhost:8080/search \
  -H 'Content-Type: application/json' \
  -d '{"query":"Python ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°","topk":5}'

# Ask with context
curl -X POST http://localhost:8080/ask \
  -H 'Content-Type: application/json' \
  -d '{"question":"ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã¯ï¼Ÿ","topk":5}'
```

### RAG Generation (MVP4)
```bash
# Non-streaming generation
curl -X POST http://localhost:8080/generate \
  -H 'Content-Type: application/json' \
  -d '{"question":"Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®åŸºæœ¬ã‚’æ•™ãˆã¦","stream":false}'

# Streaming generation
curl -X POST http://localhost:8080/generate \
  -H 'Content-Type: application/json' \
  -d '{"question":"Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®åŸºæœ¬ã‚’æ•™ãˆã¦","stream":true}'
```

### Monitoring & Admin
```bash
# Health status
curl http://localhost:8080/stats/health

# SLO metrics
curl http://localhost:8080/stats/slo

# Dashboard
curl http://localhost:8080/dashboard

# Canary status
curl http://localhost:8080/admin/canary/status
```

## ğŸ“Š Configuration

### config.yml
```yaml
# LLM Configuration
llm:
  provider: openai
  alias: default-mini
  timeout_sec: 30
  stream: true

models:
  default-mini:
    name: gpt-4o-mini
    temperature: 0.2
    max_tokens: 700
    description: "Cost-efficient, fast, good Japanese support"

# Generation settings
generation:
  context_max_tokens: 3500
  chunk_max_tokens: 1000
  max_chunks: 5
  citation_style: "bracketed"

# SLO targets
api:
  slo:
    generate:
      ttft_ms: 1200         # Time to first token
      p95_latency_ms: 6000  # Target p95 latency
      success_rate: 0.98    # Target success rate
```

## ğŸ§ª Testing

### Quick Test
```bash
# Test all major components
python3 test_mvp4.py
```

### Interactive Testing
```bash
# Start interactive mode
python -m src.cli.generate_cli --interactive

# Example session:
# Q: Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®åŸºæœ¬ã‚’æ•™ãˆã¦
# A: [Streaming response with citations]
```

### API Testing
```bash
# Test search
curl -X POST http://localhost:8080/search \
  -H 'Content-Type: application/json' \
  -d '{"query":"test","topk":3}' | jq

# Test generation
curl -X POST http://localhost:8080/generate \
  -H 'Content-Type: application/json' \
  -d '{"question":"test question","stream":false}' | jq
```

## ğŸ“ˆ Monitoring

### SLO Metrics
- **TTFT**: Time to First Token â‰¤ 1.2s
- **P95 Latency**: â‰¤ 6s
- **Success Rate**: â‰¥ 98%
- **Citation Rate**: Track citation usage

### Dashboard
Access the monitoring dashboard at:
```
http://localhost:8080/dashboard
```

### Metrics Endpoints
```bash
# Performance metrics
curl http://localhost:8080/stats/metrics

# Cache statistics
curl http://localhost:8080/stats/cache

# Rate limit status
curl http://localhost:8080/stats/rate-limit
```

## ğŸ”„ Deployment

### Canary Deployment
```bash
# Enable canary for 10% of users
curl -X POST http://localhost:8080/admin/canary/rollout \
  -H 'Content-Type: application/json' \
  -d '{"percentage": 10}'

# Check canary status
curl http://localhost:8080/admin/canary/status
```

### Backup & Recovery
```bash
# Create backup
python -m src.cli.backup_cli create

# List backups
python -m src.cli.backup_cli list

# Restore backup
python -m src.cli.backup_cli restore <backup_id>
```

## ğŸš¨ Troubleshooting

### Common Issues

1. **Import Errors**
   ```bash
   # Ensure you're in the project root
   cd /path/to/wp-chat
   source .venv/bin/activate
   ```

2. **OpenAI API Errors**
   ```bash
   # Check API key
   python -m src.cli.generate_cli --health
   ```

3. **Index Not Found**
   ```bash
   # Rebuild index
   python -m src.data.build_index
   ```

4. **Port Conflicts**
   ```bash
   # Kill existing processes
   pkill -f uvicorn
   # Start fresh
   uvicorn src.api.chat_api:app --reload --port 8080
   ```

### Logs
```bash
# Check application logs
tail -f logs/app.log

# Check error logs
tail -f logs/error.log
```

## ğŸ“š Development

### Adding New Features
1. Create feature branch
2. Implement in appropriate module
3. Add tests
4. Update documentation
5. Submit PR

### Code Style
- Follow PEP 8
- Use type hints
- Add docstrings
- Write tests

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Make changes
4. Add tests
5. Submit pull request

## ğŸ“š Documentation

- **[ğŸ“– ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¬ã‚¤ãƒ‰](guide/README.md)** - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ¦‚è¦ã¨èª­ã¿æ–¹
- **[ğŸ–¥ï¸ CLIå®Ÿè¡Œã‚¬ã‚¤ãƒ‰](guide/CLI_GUIDE.md)** - CLIãƒ„ãƒ¼ãƒ«ã®è©³ç´°ãªä½¿ç”¨æ–¹æ³•
- **[ğŸŒ APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚¬ã‚¤ãƒ‰](guide/API_GUIDE.md)** - APIã®è©³ç´°ãªä»•æ§˜ã¨ä½¿ç”¨ä¾‹
- **[ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»å¾©å…ƒã‚¬ã‚¤ãƒ‰](guide/BACKUP_GUIDE.md)** - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®ä½¿ç”¨æ–¹æ³•
- **[ğŸš¨ ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œã‚¬ã‚¤ãƒ‰](guide/INCIDENT_RUNBOOK.md)** - ç·Šæ€¥å¯¾å¿œæ‰‹é †
- **[ğŸ¯ MVP4å®Ÿè£…ã‚µãƒãƒªãƒ¼](guide/MVP4_SUMMARY.md)** - RAGç”Ÿæˆæ©Ÿèƒ½ã®å®Ÿè£…å†…å®¹
- **[âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«](config.yml)** - ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
- **[ğŸ’° ä¾¡æ ¼è¨­å®š](pricing.json)** - LLMãƒ¢ãƒ‡ãƒ«ã®ä¾¡æ ¼æƒ…å ±

## ğŸ“‹ Planning Documents

- **[ğŸ”§ æ”¹å–„å®Ÿè£…è¨ˆç”» (2025-11-01)](plans/2025-11-01-improvement-plan.md)** - å®‰å®šé‹ç”¨ã«å‘ã‘ãŸTOP8æ”¹å–„é …ç›®

## ğŸ“ Support

For issues and questions:
- Create GitHub issue
- Check troubleshooting section
- Review logs for errors
- Consult documentation guides above
